# 09 ¬∑ ML lifecycle y producci√≥n

> No todos los modelos nacen para producci√≥n.  
> Y est√° bien que as√≠ sea.

Este cap√≠tulo describe c√≥mo pensamos el **ciclo de vida de un modelo**
desde que es un experimento hasta (si corresponde) producci√≥n.

No busca ense√±ar a desplegar modelos.
Busca **poner criterios claros** para decidir
cu√°ndo algo est√° listo para dar ese paso
y qu√© responsabilidades aparecen despu√©s.

---

## El problema que estamos tratando de evitar

Sin una visi√≥n clara de lifecycle, suelen pasar cosas como:

- modelos ‚Äúen producci√≥n‚Äù sin due√±o claro
- cambios experimentales impactando usuarios reales
- degradaci√≥n silenciosa de performance
- dificultad para volver atr√°s
- confusi√≥n entre research y producto

El problema rara vez es t√©cnico.
Es **falta de criterios y ownership expl√≠citos**.

---

## El lifecycle como estados, no como pipeline r√≠gido

Pensamos el lifecycle como **estados mentales distintos**,
no como una l√≠nea recta inevitable.

Un modelo puede avanzar, quedarse, o retirarse.

```

Exploraci√≥n
‚Üì
Validaci√≥n
‚Üì
Pre-producci√≥n
‚Üì
Producci√≥n
‚Üì
Monitoreo
‚Üì
Retirada

```

No todos los modelos recorren todo el camino.
Forzar eso suele ser una mala se√±al.

---

## Etapas del lifecycle (visi√≥n pr√°ctica)

### Exploraci√≥n

- notebooks
- hip√≥tesis
- experimentos r√°pidos
- aprendizaje

Aqu√≠ prima la velocidad sobre la robustez.

---

### Validaci√≥n

- comparaci√≥n con baselines
- resultados m√°s estables
- decisiones expl√≠citas

No es producci√≥n.
Es **confirmar que vale la pena seguir**.

---

### Pre-producci√≥n

- c√≥digo m√°s estable
- contratos claros
- tests m√≠nimos
- revisi√≥n m√°s estricta

Esta etapa evita llevar experimentos fr√°giles a producci√≥n.

---

### Producci√≥n

- usuarios reales
- impacto real
- costo real del error

Ac√° cambia el juego.

---

### Monitoreo

- performance en el tiempo
- cambios en los datos
- se√±ales de degradaci√≥n

Un modelo sin monitoreo
no est√° realmente en producci√≥n.

---

### Retirada

- modelos tambi√©n se apagan
- retirar es una decisi√≥n v√°lida
- planear salida desde el inicio es sano

---

## üîí MUST ¬∑ Ownership claro

Todo modelo en producci√≥n debe tener un **owner expl√≠cito**.

El owner es responsable de:

- entender el modelo
- responder a incidentes
- decidir cu√°ndo iterar o retirar

No significa trabajar solo.
Significa que **alguien tiene la responsabilidad final**.

!!! danger
    ‚ÄúTodos lo cuidamos‚Äù  
    suele significar  
    ‚Äúnadie lo cuida‚Äù.

---

## Qu√© cambia cuando algo entra a producci√≥n

Pasar a producci√≥n implica aceptar nuevos trade-offs:

- estabilidad > novelty
- simplicidad > complejidad
- interpretabilidad > mejoras marginales
- seguridad > rapidez

Muchas ideas buenas en research
no sobreviven estos trade-offs.
Eso es normal.

---

## üîí MUST ¬∑ Monitoreo m√≠nimo esperado

Un modelo en producci√≥n debe tener,
como m√≠nimo, se√±ales de monitoreo claras.

### Qu√© monitorear (nivel b√°sico)

- m√©tricas de performance (cuando sea posible)
- distribuci√≥n de inputs
- volumen / frecuencia de uso
- errores y excepciones

No todo requiere dashboards complejos.
Requiere **visibilidad suficiente**.

---

??? example "Ejemplo ¬∑ Se√±ales de monitoreo simples"
    - ca√≠da sostenida de performance
    - cambios fuertes en la distribuci√≥n de inputs
    - aumento de errores
    - outputs fuera de rango esperado

    Estas se√±ales no explican todo,
    pero avisan **cu√°ndo mirar m√°s de cerca**.

---

## üå± DESEABLE ¬∑ Tracking y herramientas

Por defecto, el playbook es **tool-agnostic**.

Sin embargo, si el equipo o proyecto lo permite,
herramientas como **MLflow (open-source)** pueden ser √∫tiles:

- tracking de experimentos
- registro de modelos
- comparaci√≥n de runs
- metadata centralizada

MLflow puede usarse:

- en modo local
- sin costo
- sin depender de plataformas comerciales

No es obligatorio.
Es una **mejora progresiva**, no un requisito.

---

## Data drift y performance (sin obsesi√≥n)

El drift existe.
Ignorarlo no lo elimina.

Pero medir todo desde el d√≠a uno
suele generar ruido.

Regla pr√°ctica:

- empieza simple
- mide lo que puedas explicar
- agrega complejidad solo si aporta se√±al

---

## Antipatrones (se√±ales de alerta)

- ‚Äúeste notebook ya est√° en prod‚Äù
- modelos sin m√©tricas post-deploy
- nadie sabe qui√©n es el owner
- cambios silenciosos
- no hay forma clara de rollback

Estos patrones suelen indicar
que el lifecycle no est√° claro.

---

## Relaci√≥n con el resto del playbook

- [`08 ¬∑ Experimentaci√≥n`](08-experimentacion-y-trazabilidad.md) ‚Üí decide qu√© vale la pena
- [`07 ¬∑ Calidad`](07-calidad-testing-y-ci.md) ‚Üí asegura estabilidad t√©cnica
- [`09 ¬∑ Lifecycle`](09-ml-lifecycle-y-produccion.md) ‚Üí gestiona impacto real
- cap√≠tulos posteriores ‚Üí profundizan operaci√≥n

Este cap√≠tulo es donde
la experimentaci√≥n se convierte en responsabilidad.

---

## Cierre

Llevar un modelo a producci√≥n
no es un premio.
Es un **compromiso**.

Tener criterios claros,
ownership definido
y monitoreo b√°sico
no frena la innovaci√≥n.

La hace sostenible.
