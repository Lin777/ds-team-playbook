# 11 Â· Seguridad, privacidad y responsabilidad

> La mayorÃ­a de los incidentes de seguridad  
> no ocurren por mala intenciÃ³n.  
> Ocurren por descuido, presiÃ³n o falta de acuerdos claros.

Este capÃ­tulo define cÃ³mo abordamos
**seguridad y privacidad en proyectos de Data Science**,
desde una perspectiva prÃ¡ctica y responsable.

No busca convertir al equipo en expertos legales.
Busca **reducir riesgos reales** y proteger a:

- usuarios
- empresa
- equipo

---

## El problema que estamos tratando de evitar

Sin criterios claros de seguridad y privacidad, suelen aparecer:

- datos sensibles en notebooks
- credenciales expuestas â€œtemporalmenteâ€
- modelos entrenados con datos mal entendidos
- outputs que revelan informaciÃ³n no deseada
- incidentes que nadie sabe cÃ³mo manejar

El problema rara vez es falta de Ã©tica.
Es **falta de estructura y conciencia compartida**.

---

## Seguridad y privacidad en Data Science

En DS, el riesgo no estÃ¡ solo en el cÃ³digo.
TambiÃ©n estÃ¡ en:

- los datos
- los modelos
- los outputs
- las decisiones automatizadas

Por eso, la seguridad no es un â€œadd-onâ€.
Es parte del diseÃ±o.

---

## ğŸ”’ MUST Â· Principios bÃ¡sicos

Estas reglas aplican **siempre**,
independientemente del proyecto.

---

### ProtecciÃ³n de credenciales

- Las keys **no viven en el cÃ³digo**
- No se suben al repo
- No se comparten por chat
- No se hardcodean â€œsolo para probarâ€

Usamos:

- variables de entorno
- `.env` local
- secrets gestionados por la plataforma

Un leak de credenciales no es un bug menor.
Es un **incidente de seguridad**.

---

### Manejo responsable de datos

Antes de usar un dataset,
debemos poder responder:

- Â¿de dÃ³nde viene?
- Â¿quÃ© tipo de datos contiene?
- Â¿hay datos sensibles o personales?
- Â¿tenemos permiso para usarlos?

Si no podemos responder estas preguntas,
el riesgo es alto.

---

### Principio de mÃ­nimo acceso

Las personas y sistemas:

- solo acceden a lo que necesitan
- solo por el tiempo necesario

MÃ¡s acceso â‰  mÃ¡s productividad.  
MÃ¡s acceso = mÃ¡s superficie de riesgo.

---

## ğŸ”’ MUST Â· Privacidad por diseÃ±o

La privacidad no se â€œagregaâ€ al final.
Se diseÃ±a desde el inicio.

Esto implica:

- evitar usar datos sensibles si no es necesario
- anonimizar cuando sea posible
- minimizar almacenamiento de datos crudos
- pensar en los outputs, no solo en los inputs

---

??? example "Ejemplo Â· Riesgo en outputs"
    Un modelo puede no exponer datos directamente,
    pero sÃ­ permitir inferencias indebidas.

    Ejemplos:
    - revelar informaciÃ³n personal indirectamente
    - permitir reidentificaciÃ³n
    - memorizar datos sensibles

    El riesgo no siempre es obvio.

---

## ğŸŒ± DESEABLE Â· PrÃ¡cticas que reducen riesgo

Estas prÃ¡cticas no siempre son obligatorias,
pero **bajan mucho el riesgo operativo**.

---

### RevisiÃ³n de datos y modelos

Antes de mover algo a producciÃ³n:

- revisar datasets
- revisar features
- revisar outputs esperados

No es paranoia.
Es **responsabilidad profesional**.

---

### Logging consciente

Logs son poderosos,
pero tambiÃ©n peligrosos.

Buenas prÃ¡cticas:

- no loggear datos sensibles
- no loggear payloads completos sin necesidad
- revisar logs como parte del diseÃ±o

---

### Documentar decisiones sensibles

Si una decisiÃ³n tiene impacto en:

- privacidad
- seguridad
- usuarios finales

Debe quedar documentada:

- quÃ© se decidiÃ³
- por quÃ©
- quÃ© riesgos se aceptaron

Los ADRs son el lugar natural para esto.

---

## Responsabilidad en modelos y decisiones

Los modelos no son neutrales.
Reflejan:

- los datos
- los supuestos
- las decisiones humanas

Por eso, responsabilidad significa:

- entender limitaciones
- comunicar incertidumbre
- evitar sobreprometer resultados

---

## ğŸ”’ MUST Â· Ownership y accountability

Todo sistema que impacta usuarios
debe tener:

- un owner tÃ©cnico
- un punto claro de contacto

Cuando algo falla,
la pregunta no es â€œÂ¿quiÃ©n tuvo la culpa?â€,
sino:
> â€œÂ¿quiÃ©n puede ayudar a resolverlo?â€

---

## Antipatrones (seÃ±ales de alerta)

- â€œesto es solo para testingâ€
- datasets sin origen claro
- logs con datos sensibles
- nadie sabe quiÃ©n es el owner
- asumir que seguridad es problema de otro equipo

Estos patrones suelen preceder incidentes reales.

---

## RelaciÃ³n con el resto del playbook

- [`03 Â· Entornos`](03-entornos-y-dependencias.md) â†’ evita leaks accidentales
- [`05 Â· EstÃ¡ndares`](05-estandares-de-codigo.md) â†’ cÃ³digo responsable
- [`09 Â· Lifecycle`](09-ml-lifecycle-y-produccion.md) â†’ impacto en producciÃ³n
- [`10 Â· Rituales`](10-rituales-feedback-y-crecimiento.md) â†’ conversaciones difÃ­ciles a tiempo

La seguridad no vive en un solo capÃ­tulo.
Pero este capÃ­tulo la **hace explÃ­cita**.

---

## Cierre

La seguridad perfecta no existe.
La irresponsabilidad sÃ­.

Tomar decisiones conscientes,
documentarlas
y reducir riesgos innecesarios
es parte del trabajo profesional en Data Science.

No es un freno.
Es una forma de cuidar lo que construimos.
